{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICE'] = ''\n",
    "\n",
    "import argparse\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"text_recognizer\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "from text_recognizer.data import EMNISTLines2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More challenging EMNISTLines\n",
    "\n",
    "Now that we've seen the `IAMLines` dataset, we can make our synthetic dataset look more like it by changing the shape of the canvas into which we embed the sentence crops, and by adding data augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EMNISTLines2(args=argparse.Namespace())\n",
    "dataset.prepare_data()\n",
    "dataset.setup()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_label_to_string(y, dataset=dataset):\n",
    "    # NOTE: we ignore padding tokens\n",
    "    return ''.join([dataset.mapping[i] for i in y if i != 3])\n",
    "\n",
    "y_example = dataset.data_train[0][1]\n",
    "print(y_example, y_example.shape)\n",
    "convert_y_label_to_string(y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train\n",
    "\n",
    "X, Y = next(iter(dataset.train_dataloader()))\n",
    "for i in range(10):\n",
    "    x, y = X[i], Y[i]\n",
    "    sentence = convert_y_label_to_string(y) \n",
    "    plt.matshow(x.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "\n",
    "X, Y = next(iter(dataset.test_dataloader()))\n",
    "for i in range(10):\n",
    "    x, y = X[i], Y[i]\n",
    "    sentence = convert_y_label_to_string(y) \n",
    "    plt.matshow(x.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See predictions of a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from text_recognizer.lit_models import TransformerLitModel\n",
    "from text_recognizer.models import LineCNNTransformer\n",
    "\n",
    "model = LineCNNTransformer(\n",
    "    data_config=dataset.config(),\n",
    "    args=argparse.Namespace()\n",
    ")\n",
    "lit_model = TransformerLitModel.load_from_checkpoint(\n",
    "    '../training/logs/default_fsdl-text-recognizer-2021-training/469_3ocpqryn/checkpoints/epoch=125-step=5039.ckpt',\n",
    "    model=model,\n",
    "    args=argparse.Namespace()\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    x, y = dataset.data_train[i]\n",
    "    pred = lit_model(x.unsqueeze(0))\n",
    "    pred_sentence = ''.join(dataset.mapping[_] for _ in pred[0].tolist() if _ != 3)\n",
    "    true_sentence = convert_y_label_to_string(y) \n",
    "    plt.matshow(x.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(pred_sentence)\n",
    "    \n",
    "for i in range(5):\n",
    "    x, y = dataset.data_test[i]\n",
    "    pred = lit_model(x.unsqueeze(0))\n",
    "    pred_sentence = ''.join(dataset.mapping[_] for _ in pred[0].tolist() if _ != 3)\n",
    "    true_sentence = convert_y_label_to_string(y) \n",
    "    plt.matshow(x.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title(pred_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
